{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "biological-success",
   "metadata": {},
   "source": [
    "# 1.Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "peripheral-exercise",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading Execution Data\n",
    "with open(\"../Data/1/Execution_Data.csv\", \"r\") as f:\n",
    "    fr = f.readlines()\n",
    "_CPU = []\n",
    "_GPU = []\n",
    "for val in fr:\n",
    "    val = val.strip().split(',')\n",
    "    if(val[1]=='0'):\n",
    "        _CPU.append(val)\n",
    "    elif(val[1]=='1'):\n",
    "        _GPU.append(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "sporting-velvet",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating Average Execution Time w.r.t features\n",
    "_Avg_CPU = []\n",
    "for val in _CPU:\n",
    "    _T_Feat = val[0]\n",
    "    _T_Time = val[2]\n",
    "    if(len(_Avg_CPU)>0):\n",
    "        if(_Avg_CPU[-1][0]==_T_Feat):\n",
    "            _Avg_CPU[-1][1] = float(_Avg_CPU[-1][1])+float(_T_Time)\n",
    "            _Avg_CPU[-1][2]+=1\n",
    "        else:\n",
    "            _Avg_CPU.append([_T_Feat,_T_Time,1])\n",
    "    else:\n",
    "        _Avg_CPU.append([_T_Feat,_T_Time,1])\n",
    "        \n",
    "_Avg_GPU = []\n",
    "for val in _GPU:\n",
    "    _T_Feat = val[0]\n",
    "    _T_Time = val[2]\n",
    "    if(len(_Avg_GPU)>0):\n",
    "        if(_Avg_GPU[-1][0]==_T_Feat):\n",
    "            _Avg_GPU[-1][1] = float(_Avg_GPU[-1][1])+float(_T_Time)\n",
    "            _Avg_GPU[-1][2]+=1\n",
    "        else:\n",
    "            _Avg_GPU.append([_T_Feat,_T_Time,1])\n",
    "    else:\n",
    "        _Avg_GPU.append([_T_Feat,_T_Time,1])\n",
    "for i in range(0,max(len(_Avg_CPU),len(_Avg_GPU))):\n",
    "    if(i<len(_Avg_CPU)):\n",
    "        _Avg_CPU[i] = {\"Features\": _Avg_CPU[i][0],\"Execution_Time\": _Avg_CPU[i][1]/_Avg_CPU[i][2]}\n",
    "    if(i<len(_Avg_GPU)):\n",
    "        _Avg_GPU[i] = {\"Features\": _Avg_GPU[i][0],\"Execution_Time\": _Avg_GPU[i][1]/_Avg_GPU[i][2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "dutch-suspect",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering complete information and saving\n",
    "_Final = []\n",
    "for i in range(0,len(_Avg_CPU)):\n",
    "    _T_CPU = _Avg_CPU[i]\n",
    "    _T_GPU = next((item for item in _Avg_GPU if item[\"Features\"] == _T_CPU[\"Features\"]), None)\n",
    "    if(_T_GPU!=None):\n",
    "        _Final.append([_T_CPU[\"Features\"],_T_CPU[\"Execution_Time\"],_T_GPU[\"Execution_Time\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "occupied-helping",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Conversion to suitable format\n",
    "for i in range(0,len(_Final)):\n",
    "    _Speed_up = _Final[i][1]-_Final[i][2]\n",
    "    if(_Speed_up>0):\n",
    "        _Final[i][1] = _Speed_up\n",
    "        _Final[i][2] = 1\n",
    "    else:\n",
    "        _Final[i][1] = _Speed_up*-1\n",
    "        _Final[i][2] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "occasional-reggae",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../Data/2/Classification_data.csv\", \"w\") as f:\n",
    "    f.write(\"[1]-Total no of Return statement,[2]-Total no of Control Statement,[3]-Total no of Allocation instruction,[4]-Total no of Load Instructions,[5]-Total no of Store Instructions,[6]-Total no of Multiplication (Float Datatype) Operation,[7]-Total no of Addition(Integer Datatype) Instruction,[8]-Total no of Multiplication(Integer Datatype) Instruction,[9]-Total no of Division(Float Datatype) instruction,[10]-Total no of Division(Integer Datatype) instruction,[11]-Total no of Condition Check instruction,[12]-Total no of Addition(Float Datatype) instruction,[13]-Total no of Addition(Integer Datatype) instruction,[14]-Total no of Subtraction(Float Datatype) instruction,[15]-Total no of Subtraction(Integer Datatype) instruction,[16]-Total no of Function Call instruction,[17]-Total no of Functions,[18]-Total no of Blocks,[19]-Total no of Instructions,[20]-Total no of Float Operation,[21]-Total no of Integer Operation,[22]-Total no of Loop Operation,[23]-Total no of Loop,[24]-Ram,[25]-CPU Rank,[26]-GPU Rank,[27]-Matrix Size,[28]-Prefered Device\\n\")\n",
    "with open(\"../Data/2/Regression_Data.csv\", \"w\") as f:\n",
    "    f.write(\"[1]-Total no of Return statement,[2]-Total no of Control Statement,[3]-Total no of Allocation instruction,[4]-Total no of Load Instructions,[5]-Total no of Store Instructions,[6]-Total no of Multiplication (Float Datatype) Operation,[7]-Total no of Addition(Integer Datatype) Instruction,[8]-Total no of Multiplication(Integer Datatype) Instruction,[9]-Total no of Division(Float Datatype) instruction,[10]-Total no of Division(Integer Datatype) instruction,[11]-Total no of Condition Check instruction,[12]-Total no of Addition(Float Datatype) instruction,[13]-Total no of Addition(Integer Datatype) instruction,[14]-Total no of Subtraction(Float Datatype) instruction,[15]-Total no of Subtraction(Integer Datatype) instruction,[16]-Total no of Function Call instruction,[17]-Total no of Functions,[18]-Total no of Blocks,[19]-Total no of Instructions,[20]-Total no of Float Operation,[21]-Total no of Integer Operation,[22]-Total no of Loop Operation,[23]-Total no of Loop,[24]-Ram,[25]-CPU Rank,[26]-GPU Rank,[27]-Matrix Size,[28]-Speed up\\n\")\n",
    "    \n",
    "for i in range(0,len(_Final)):\n",
    "    v1 = _Final[i][0].split('-')\n",
    "    for j in range(0,len(v1)):\n",
    "        v1[j]=int(v1[j])\n",
    "    v1.append(_Final[i][1])\n",
    "    v2 = _Final[i][0].split('-')\n",
    "    for j in range(0,len(v2)):\n",
    "        v2[j]=int(v2[j])\n",
    "    v2.append(_Final[i][2])\n",
    "    with open(\"../Data/2/Classification_data.csv\", \"a\") as f:\n",
    "        f.write(str(v2).split('[')[1].split(']')[0]+\"\\n\")\n",
    "    with open(\"../Data/2/Regression_Data.csv\", \"a\") as f:\n",
    "        f.write(str(v1).split('[')[1].split(']')[0]+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instructional-manual",
   "metadata": {},
   "source": [
    "# 2. Training Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "regulated-adoption",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "sound-swift",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class = pd.read_csv(\"../Data/2/Classification_data.csv\")\n",
    "data = df_class[  df_class.columns[0:-1] ]\n",
    "label = df_class[ df_class.columns[-1] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "aware-henry",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split( data, label, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "divine-turkey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC()\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "sharing-motor",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict( x_test  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "authorized-pantyhose",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is :  88.67924528301887 %\n"
     ]
    }
   ],
   "source": [
    "print ( \"Accuracy is : \" , len(y_test [ y_pred == y_test ] )/ len(y_test)*100, \"%\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "expensive-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# save the classifier\n",
    "with open('trained_classifier.pkl', 'wb') as fid:\n",
    "    pickle.dump( clf, fid)    \n",
    "\n",
    "# load it again\n",
    "#with open('trained_classifier.pkl', 'rb') as fid:\n",
    "    #clf = cPickle.load(fid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "freelance-dollar",
   "metadata": {},
   "source": [
    "# 3. Training Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "existing-lodge",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regr = pd.read_csv(\"../Data/2/Regression_Data.csv\")\n",
    "data = df_regr[  df_regr.columns[0:-1] ]\n",
    "label = df_regr[ df_regr.columns[-1] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "spoken-ladder",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split( data, label, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "micro-bidder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=5, n_estimators=200, random_state=0)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "regr = RandomForestRegressor(n_estimators=200, max_depth=5, random_state=0)\n",
    "\n",
    "regr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "instructional-fashion",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regr.predict( x_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "modular-mambo",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.259578379768381"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error( list( y_test ) , list( y_pred ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "respiratory-fundamentals",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# save the classifier\n",
    "with open('trained_regressor.pkl', 'wb') as fid:\n",
    "    pickle.dump( regr, fid)\n",
    "\n",
    "# load it again\n",
    "#with open('trained_regressor.pkl', 'rb') as fid:\n",
    "    #regr = cPickle.load(fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agreed-microwave",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
